# IBM-Project-11148-1659270620
Real-Time Communication System Powered by AI for Specially Abled

Proposed System: Sign Language Recognition

Sign language is the mode of communication which uses visual ways like expressions, hand gestures, 
and body movements to convey meaning.  This is  extremely helpful for people who face difficulty with hearing or speaking.

Sign language recognition refers to the conversion of these gestures into words or alphabets for deaf people of existing 
formally spoken languages or gestures into audio for blind people.  Thus, conversion of sign language into words or audio 
by an algorithm or a model can help bridge the gap between people with hearing or speaking impairment and the rest of the 
world.

We are using mediapipe hollsitic library to fetch the body and facial posture which will be used to train our model.
The model is trained on a large dataset which almost consists of 400 different words.

Video Link - https://drive.google.com/file/d/1YM_p-FXoprWMP7EKg_IvkvsWXa-xqCum/view?usp=sharing

Report Link - https://drive.google.com/file/d/13yi73xwHASiFSwSqvYWR9mq7SoGREHEp/view?usp=share_link

UAT Report - https://drive.google.com/file/d/1hrZZPCrlBsB9QHr9cvhIW_VNEs65yB-y/view?usp=share_link

Performance Test Report - https://drive.google.com/file/d/10XcM8gEGnqHj9l2G12OMmUWE4IY9H7Kh/view?usp=share_link

Flask - https://drive.google.com/file/d/1rdDla0NE5p_khmlq0jJJxMERoQyu_06t/view?usp=sharing